---
title: "Apple Silicon用に最適化されたML用のライブラリMLXで最速Whisperを試す"
emoji: "🍣"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["ml", "mlx", "whisper"]
published: true
publication_name: noplan_inc
published_at: 2023-12-08

---

## はじめに

こんにちは〜！皆様いかがお過ごしでしょうか？　no plan inc. CTOの [@serinuntius](https://twitter.com/_serinuntius) です。
これは[no plan inc.の Advent Calendar 2023](https://qiita.com/advent-calendar/2023/noplan_inc)の8日目の記事です。

一昨日ぐらいに海外で話題になってましたが、MLXというApple Siliconに最適化された[MLX](https://github.com/ml-explore/mlx)というライブラリ・フレームワークが発表されました。
そちらのexampleにあるwhisperを動かしてみようと思います。

## インストールする
今回は `Python 3.8.18`を使って動かしていきます。

まずはexampleをcloneしましょう
```bash
git clone git@github.com:ml-explore/mlx-examples.git
cd mlx-exmaples
```

mlxをinstallしましょう。
```bash
pip install mlx
```

whisperのdirに入って、requirements.txtをインストールしましょう。

```bash
cd whisper
pip install -r requirements.txt
```

もし ffmpegが入ってない方は予め入れておきましょう。

```bash
brew install ffmpeg
```

## 適当なAudioファイルを用意する
なんでもいいですが、自分の声で動かせた方が面白いでしょうから、Quicktime Playerで適当にAudioを録音して、whisperのdirに配置しておきましょう。

## 動かしてみる
```bash
python
>>> import whisper
>>> speach_file = "input.m4a"
>>> text = whisper.transcribe(speech_file)["text"]
>>> print(text)
```

短いファイルだと正常に動くと思います。１時間を超えるファイルを読ませると、以下のエラーが発生しました。

```
    text = whisper.transcribe(speech_file)["text"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.../.../mlx-examples/whisper/whisper/transcribe.py", line 303, in transcribe
    timestamps = tokens[timestamp_tokens.nonzero().flatten()]
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'tuple' object has no attribute 'flatten'
```

このエラーは普通に実装ミスってるぽくって、今日現在すでにPRが出されてます。

`whisper/whisper/transcribe.py` の 303 行目を以下のように変更すると動くはずです。

```python
# before: timestamps = tokens[timestamp_tokens.nonzero().flatten()]
# after
timestamps = tokens[timestamp_tokens.nonzero()[0]]
```

Issueで報告して、PR作ろうかと思いましたが、既に両方ともありました。世界すごい。OSSすごい。
感動しました。

## 性能どうなの
アドカレの入稿期限的に間に合わないので、めちゃくちゃ適当な記憶のベンチで大変恐縮ですが

１時間以上のMTGの議事録をぶち込んだ時に、同じマシンで動かしてるDockerの中で動かしてるWhisperでは30分以上かかってたと思います。
MLX版では **2:36** で処理できました。びっくりするほど早かったです。精度も特に気にならなかったです。

あとで時間ある時に精度とベンチ含めやり直したいです。

## まとめ

- MLXやばすぎる
- ついにMLでもAppleが本気出してきたか？
- MLX使って実装すると物にもよるが10xぐらいの高速化が期待できる？


## no plan株式会社について
- no plan株式会社は **「テクノロジーの力でZEROから未来を創造する、精鋭クリエイター集団」** です。
- ブロックチェーン/AI技術をはじめとした、Webサイト開発、ネイティブアプリ開発、チーム育成、などWebサービス全般の開発から運用や教育、支援なども行っています。よくわからない、ふわふわしたノープラン状態でも大丈夫！ご一緒にプランを立てていきましょう！
- [no plan株式会社について](https://noplan-inc.com)
- [no plan株式会社 | web3実績](https://noplan-inc.com/web3)
- [no plan株式会社 | ブログ一覧](https://noplan-inc.com/blog)

エンジニアの採用も積極的に行なっていますので、興味がある方は是非ご連絡ください！
- [CTOのDMはこちら](https://twitter.com/_serinuntius)


## 参考文献
https://github.com/ml-explore/mlx
https://github.com/ml-explore/mlx-examples/issues/31
https://github.com/ml-explore/mlx-examples/pull/12